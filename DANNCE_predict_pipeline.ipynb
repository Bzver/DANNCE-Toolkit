{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "\n",
    "from dannce.cli import get_parser, build_clarg_params \n",
    "from dannce.interface import dannce_predict, sdannce_predict, com_predict\n",
    "from dannce.engine.utils.vis import visualize_pose_predictions\n",
    "from dannce.engine.data.io import load_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNNING_MODE = \"predict\"\n",
    "MODEL_TYPE = \"sdannce\"\n",
    "\n",
    "EXPROOT = '/mnt/d/Project/SDANNCE-Models/4CAM-3D-2ETUP/SD-20250526'\n",
    "\n",
    "MODEL_CHECKPOINT = \"/mnt/d/Project/SDANNCE-Models/4CAM-3D-2ETUP/Weights/checkpoint-SDANNCE-best.pth\"\n",
    "COM_CHECKPOINT = \"/mnt/d/Project/SDANNCE-Models/4CAM-3D-2ETUP/Weights/checkpoint-COM-best-epoch1000.pth\"\n",
    "\n",
    "CONFIG = '/home/bezver/sdannce/configs/custom_sdannce_config.yaml'\n",
    "COM_CONFIG = '/home/bezver/sdannce/configs/custom_com_config.yaml'\n",
    "\n",
    "N_ANIMALS = 1\n",
    "INFERENCE_ALL = True\n",
    "STEPSIZE = 2000\n",
    "\n",
    "# Only used when INFERENCE_ALL is FALSE\n",
    "STARTFRAME = 0\n",
    "ENDFRAME = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_io_yaml(\n",
    "    exproot=EXPROOT,\n",
    "    n_animals=N_ANIMALS\n",
    "):\n",
    "    os.makedirs(exproot, exist_ok=True)\n",
    "\n",
    "    config = {\n",
    "        'com_train_dir': './COM/train00',\n",
    "        'com_predict_dir': './COM/predict00',\n",
    "        'com_exp': None,\n",
    "        'exp': None,\n",
    "        'dannce_train_dir': './DANNCE/train00/',\n",
    "        'dannce_predict_dir': './DANNCE/predict00/',\n",
    "        'com_file': './COM/predict00/com3d.mat',\n",
    "        'use_npy': True,\n",
    "        'rand_view_replace': True,\n",
    "        'n_rand_views': 4,\n",
    "        'n_instances': n_animals,\n",
    "        'mirror_augmentation': False,\n",
    "        'augment_hue': False,\n",
    "        'augment_brightness': False\n",
    "    }\n",
    "    \n",
    "    output_file = os.path.join(exproot, 'io.yaml')\n",
    "    with open(output_file, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(f\"YAML config saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_com(\n",
    "    exproot=EXPROOT,\n",
    "    n_animals=N_ANIMALS,\n",
    "    com_checkpoint=COM_CHECKPOINT,\n",
    "    config=COM_CONFIG\n",
    "):\n",
    "    # parameter arguments\n",
    "    arguments = {\n",
    "            \"com-predict-weights\": com_checkpoint,\n",
    "            \"com-predict-dir\": \"./COM/predict00\",\n",
    "            \"batch-size\": 8,\n",
    "            \"n-instances\": n_animals,\n",
    "    }\n",
    "    \n",
    "    os.chdir(exproot)\n",
    "\n",
    "    cmds = ['com',RUNNING_MODE, \"com\", config]\n",
    "\n",
    "    for k, v in arguments.items():\n",
    "        cmds += [f\"--{k}\", str(v)]\n",
    "\n",
    "    sys.argv = cmds\n",
    "    args = get_parser()\n",
    "    params = build_clarg_params(\n",
    "        args,\n",
    "        dannce_net=(args.mode == \"dannce\") | (args.mode == \"sdannce\"),\n",
    "        prediction=(args.command == \"predict\"),\n",
    "    )\n",
    "    com_predict(params)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_inference(\n",
    "    exproot=EXPROOT,\n",
    "    n_animals=N_ANIMALS,\n",
    "    config=CONFIG,\n",
    "    model_checkpoint=MODEL_CHECKPOINT,\n",
    "    com_file=\"./COM/predict00/com3d.mat\",\n",
    "    dannce_predict_dir=\"./DANNCE/predict00\",\n",
    "    max_num_samples=ENDFRAME,\n",
    "    start_sample=STARTFRAME,\n",
    "):\n",
    "    # parameter arguments\n",
    "    arguments = {\n",
    "        \"dannce-predict-model\": model_checkpoint,\n",
    "        \"dannce-predict-dir\": dannce_predict_dir,\n",
    "        \"com-file\": com_file,\n",
    "        \"start-sample\": start_sample,\n",
    "        \"max-num-samples\": max_num_samples,\n",
    "        \"batch-size\": 1,\n",
    "        \"n-instances\": n_animals,\n",
    "    }\n",
    "\n",
    "    # DANNCE must run within the experiment directory\n",
    "    os.chdir(exproot)\n",
    "\n",
    "    # compose the DANNCE command\n",
    "    cmds = ['dannce', RUNNING_MODE, MODEL_TYPE, config]\n",
    "    # override default arguments if specified\n",
    "    for k, v in arguments.items():\n",
    "        cmds += [f\"--{k}\", str(v)]\n",
    "\n",
    "    # set arguments and launch command\n",
    "    sys.argv = cmds\n",
    "    args = get_parser()\n",
    "    params = build_clarg_params(\n",
    "        args,\n",
    "        dannce_net=(args.mode == \"dannce\") | (args.mode == \"sdannce\"),\n",
    "        prediction=(args.command == \"predict\"),\n",
    "    )\n",
    "    sdannce_predict(params)\n",
    "\n",
    "    # please manually clear the CUDA cache to avoid OOM\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # visualize predictions\n",
    "    video_path = visualize_pose_predictions(\n",
    "        exproot=exproot,\n",
    "        expfolder=args.dannce_predict_dir,\n",
    "        datafile=f\"save_data_AVG{start_sample}.mat\",        \n",
    "        n_frames=max_num_samples - start_sample,\n",
    "        start_frame=start_sample,\n",
    "        cameras=\"1,2,3,4\",\n",
    "        animal=\"rat16\",\n",
    "        n_animals=n_animals,\n",
    "        zoom_in=True,\n",
    "        zoom_window_size=80\n",
    "    )\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmented_and_call_inference(\n",
    "    inference_all = INFERENCE_ALL,\n",
    "    sync_path = os.path.join(EXPROOT,\"sync_dannce.mat\"),\n",
    "    duration = ENDFRAME - STARTFRAME,\n",
    "    step_size = STEPSIZE,\n",
    "):\n",
    "    if not inference_all and duration <= step_size:\n",
    "        video_path = launch_inference()\n",
    "        return video_path\n",
    "    else: # If inference_all is True, perform segmented inference.\n",
    "        data_sync = load_sync(sync_path)\n",
    "\n",
    "        # Get the total number of frames from the 'data_frame' field in the loaded sync data.\n",
    "        total_frames = len(data_sync[0]['data_frame'][0])\n",
    "        print(f\"Found {total_frames} frames in {EXPROOT} videos\")\n",
    "\n",
    "        # Calculate segments\n",
    "        num_segment = total_frames // step_size\n",
    "        final_segment = total_frames % step_size\n",
    "        if final_segment > 0:\n",
    "            num_segment += 1\n",
    "        else:\n",
    "            final_segment = step_size\n",
    "        \n",
    "        video_path = []\n",
    "\n",
    "        # Loop through each segment to perform inference\n",
    "        for i in range(num_segment):\n",
    "            start_frame = i * step_size\n",
    "            end_frame = (i+1) * step_size if i != num_segment-1 else i * step_size + final_segment\n",
    "\n",
    "            # Progress bar\n",
    "            percent = (i + 1) / num_segment * 100\n",
    "            bar_length = 50\n",
    "            filled_length = int(bar_length * (i + 1) // num_segment)\n",
    "            bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)\n",
    "\n",
    "            sys.stdout.write(f'\\rProgress: |{bar}| {percent:.2f}% ({i + 1}/{num_segment} segments) -  ')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # Call the inference function for the current segment\n",
    "            video_path.append(launch_inference(max_num_samples=end_frame,start_sample=start_frame))\n",
    "\n",
    "        sys.stdout.write('\\nDone!\\n')\n",
    "        sys.stdout.flush()\n",
    "        return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"io.yaml\" not in os.listdir(EXPROOT):\n",
    "    generate_io_yaml()\n",
    "\n",
    "COM_dir = os.path.join(EXPROOT,\"com\",\"predict00\")\n",
    "os.makedirs(COM_dir,exist_ok=True)\n",
    "\n",
    "if \"com3d.mat\" not in os.listdir(COM_dir):\n",
    "    print(f\"COM file not found in {COM_dir}, predicting COM now...\")\n",
    "    predict_com()\n",
    "\n",
    "if \"sync_dannce.mat\" not in os.listdir(EXPROOT):\n",
    "    sync_file = [f for f in os.listdir(EXPROOT) if f.endswith(\"_dannce.mat\")]\n",
    "    if sync_file:\n",
    "        sync_path = os.path.join(EXPROOT, sync_file[0])\n",
    "        video_path = segmented_and_call_inference(sync_path=sync_path)\n",
    "        print(f\"Inferenced video saved to {video_path}\")\n",
    "    else:\n",
    "        print(\"Error: No sync file found in project folder.\")\n",
    "else:\n",
    "    video_path = segmented_and_call_inference()\n",
    "    print(f\"Inferenced video saved to {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdannce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
