{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dannce.cli import get_parser, build_clarg_params, load_params\n",
    "from dannce.interface import dannce_predict, sdannce_predict, com_predict\n",
    "from dannce.engine.utils.vis import visualize_pose_predictions\n",
    "from dannce.engine.data.io import load_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNNING_MODE = \"predict\"\n",
    "MODEL_TYPE = \"sdannce\"\n",
    "\n",
    "EXPROOT = '/mnt/d/Project/SDANNCE-Models/666-6CAM/SD-20250910-c55toe1-5cam/'\n",
    "\n",
    "MODEL_CHECKPOINT = \"/mnt/d/Project/SDANNCE-Models/555-5CAM/Weights/checkpoint-SDANNCE-5cam-best.pth\"\n",
    "COM_CHECKPOINT = \"/mnt/d/Project/SDANNCE-Models/555-5CAM/Weights/checkpoint-COM-5cam-best-epoch1000.pth\"\n",
    "\n",
    "CONFIG_FOLDER = '/home/bezver/sdannce/configs/'\n",
    "\n",
    "N_ANIMALS = 1\n",
    "N_VIEWS = 5\n",
    "INFERENCE_ALL = False\n",
    "STEPSIZE = 10000 # Decrease this if encountered OOM\n",
    "SKIP_VIDEO = True\n",
    "\n",
    "# Only used when INFERENCE_ALL is FALSE\n",
    "STARTFRAME = 64000\n",
    "ENDFRAME = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_VIEWS == 4:\n",
    "    CONFIG = os.path.join(CONFIG_FOLDER, \"custom_sdannce_config.yaml\")\n",
    "    COM_CONFIG = os.path.join(CONFIG_FOLDER, \"custom_com_config.yaml\")\n",
    "else:\n",
    "    CONFIG = os.path.join(CONFIG_FOLDER, f\"custom{N_VIEWS}_sdannce_config.yaml\")\n",
    "    COM_CONFIG = os.path.join(CONFIG_FOLDER, f\"custom{N_VIEWS}_com_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_io_yaml(\n",
    "    exproot=EXPROOT,\n",
    "):\n",
    "    os.makedirs(exproot, exist_ok=True)\n",
    "\n",
    "    config = {\n",
    "        'com_train_dir': './COM/train00',\n",
    "        'com_predict_dir': './COM/predict00',\n",
    "        'com_exp': None,\n",
    "        'exp': None,\n",
    "        'dannce_train_dir': './DANNCE/train00/',\n",
    "        'dannce_predict_dir': './DANNCE/predict00/',\n",
    "        'com_file': './COM/predict00/com3d.mat',\n",
    "        'use_npy': True,\n",
    "        'rand_view_replace': True,\n",
    "        'mirror_augmentation': False,\n",
    "        'augment_hue': False,\n",
    "        'augment_brightness': False\n",
    "    }\n",
    "    \n",
    "    output_file = os.path.join(exproot, 'io.yaml')\n",
    "    with open(output_file, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(f\"YAML config saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_com(\n",
    "    exproot=EXPROOT,\n",
    "    n_animals=N_ANIMALS,\n",
    "    com_checkpoint=COM_CHECKPOINT,\n",
    "    config=COM_CONFIG\n",
    "):\n",
    "    # parameter arguments\n",
    "    arguments = {\n",
    "            \"com-predict-weights\": com_checkpoint,\n",
    "            \"com-predict-dir\": \"./COM/predict00\",\n",
    "            \"batch-size\": 16,\n",
    "            \"n-instances\": n_animals,\n",
    "    }\n",
    "    \n",
    "    os.chdir(exproot)\n",
    "\n",
    "    cmds = ['com',RUNNING_MODE, \"com\", config]\n",
    "\n",
    "    for k, v in arguments.items():\n",
    "        cmds += [f\"--{k}\", str(v)]\n",
    "\n",
    "    sys.argv = cmds\n",
    "    args = get_parser()\n",
    "    params = build_clarg_params(\n",
    "        args,\n",
    "        dannce_net=(args.mode == \"dannce\") | (args.mode == \"sdannce\"),\n",
    "        prediction=(args.command == \"predict\"),\n",
    "    )\n",
    "    com_predict(params)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_inference(\n",
    "    exproot=EXPROOT,\n",
    "    n_animals=N_ANIMALS,\n",
    "    config=CONFIG,\n",
    "    model_checkpoint=MODEL_CHECKPOINT,\n",
    "    com_file=\"./COM/predict00/com3d.mat\",\n",
    "    dannce_predict_dir=\"./DANNCE/predict00\",\n",
    "    max_num_samples=ENDFRAME,\n",
    "    start_sample=STARTFRAME,\n",
    "    skip_video=SKIP_VIDEO\n",
    "): # Adapted from SDANNCE Repo\n",
    "    # parameter arguments\n",
    "    arguments = {\n",
    "        \"dannce-predict-model\": model_checkpoint,\n",
    "        \"dannce-predict-dir\": dannce_predict_dir,\n",
    "        \"com-file\": com_file,\n",
    "        \"start-sample\": start_sample,\n",
    "        \"max-num-samples\": max_num_samples,\n",
    "        \"batch-size\": 1,\n",
    "        \"n-instances\": n_animals,\n",
    "    }\n",
    "\n",
    "    # DANNCE must run within the experiment directory\n",
    "    os.chdir(exproot)\n",
    "\n",
    "    # compose the DANNCE command\n",
    "    cmds = ['dannce', RUNNING_MODE, MODEL_TYPE, config]\n",
    "    # override default arguments if specified\n",
    "    for k, v in arguments.items():\n",
    "        cmds += [f\"--{k}\", str(v)]\n",
    "\n",
    "    # set arguments and launch command\n",
    "    sys.argv = cmds\n",
    "    args = get_parser()\n",
    "    params = build_clarg_params(\n",
    "        args,\n",
    "        dannce_net=(args.mode == \"dannce\") | (args.mode == \"sdannce\"),\n",
    "        prediction=(args.command == \"predict\"),\n",
    "    )\n",
    "    sdannce_predict(params)\n",
    "\n",
    "    # please manually clear the CUDA cache to avoid OOM\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if skip_video:\n",
    "        return\n",
    "    \n",
    "    # visualize predictions\n",
    "    video_path = visualize_pose_predictions(\n",
    "        exproot=exproot,\n",
    "        expfolder=args.dannce_predict_dir,\n",
    "        datafile=f\"save_data_AVG{start_sample}.mat\",        \n",
    "        n_frames=max_num_samples - start_sample,\n",
    "        start_frame=start_sample,\n",
    "        cameras=','.join(map(str, range(1, N_VIEWS+1))),\n",
    "        animal=\"rat16\",\n",
    "        n_animals=n_animals,\n",
    "        zoom_in=True,\n",
    "        zoom_window_size=80\n",
    "    )\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pred(predict_path=None):  # Adapted from SDANNCE Repo\n",
    "    # Get all of the paths\n",
    "    if predict_path is None:\n",
    "        # Try to get it from io.yaml\n",
    "        params = load_params(os.path.join(EXPROOT, \"io.yaml\"))\n",
    "        if params[\"dannce_predict_dir\"] is None:\n",
    "            raise ValueError(\n",
    "                \"Either predict_path (clarg) or dannce_predict_dir (in io.yaml) must be specified for merge\"\n",
    "            )\n",
    "        else:\n",
    "            param_dir = params[\"dannce_predict_dir\"]\n",
    "            predict_path = os.path.join(EXPROOT, param_dir.split(\"./\")[1])\n",
    "\n",
    "    print(f\"predict_path:{predict_path}\")\n",
    "    pred_files = [\n",
    "        f for f in os.listdir(predict_path) if f.startswith(\"save_data_AVG\") and f != (\"save_data_AVG.mat\")\n",
    "    ]\n",
    "    pred_inds = [\n",
    "        int(f.split(\"save_data_AVG\")[-1].split(\".\")[0])\n",
    "        for f in pred_files\n",
    "    ]\n",
    "    pred_files = [pred_files[i] for i in np.argsort(pred_inds)]\n",
    "    if len(pred_files) == 0:\n",
    "        raise FileNotFoundError(\"No prediction files were found.\")\n",
    "\n",
    "    # Load all of the data\n",
    "    pred, data, p_max, sampleID = [], [], [], []\n",
    "    for file in pred_files:\n",
    "        M = loadmat(os.path.join(predict_path, file))\n",
    "        pred.append(M[\"pred\"])\n",
    "        data.append(M[\"data\"])\n",
    "        p_max.append(M[\"p_max\"])\n",
    "        sampleID.append(M[\"sampleID\"])\n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    p_max = np.concatenate(p_max, axis=0)\n",
    "    sampleID = np.concatenate(sampleID, axis=1)\n",
    "\n",
    "    # save to a single file.\n",
    "    fn = os.path.join(\n",
    "        predict_path, \"save_data_AVG\" + \".mat\"\n",
    "    )\n",
    "    savemat(\n",
    "        fn,\n",
    "        {\n",
    "            \"pred\": pred,\n",
    "            \"data\": data,\n",
    "            \"p_max\": p_max,\n",
    "            \"sampleID\": sampleID,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmented_and_call_inference(\n",
    "    inference_all = INFERENCE_ALL,\n",
    "    sync_path = os.path.join(EXPROOT,\"sync_dannce.mat\"),\n",
    "    step_size = STEPSIZE,\n",
    "    start_frame = STARTFRAME,\n",
    "    end_frame = ENDFRAME,\n",
    "):\n",
    "    data_sync = load_sync(sync_path)\n",
    "    video_total_frames = len(data_sync[0]['data_frame'][0])\n",
    "\n",
    "    if end_frame == -1:\n",
    "        end_frame = video_total_frames\n",
    "    duration = end_frame - start_frame\n",
    "\n",
    "    if inference_all:\n",
    "        start_frame = 0\n",
    "\n",
    "    if not inference_all and duration <= step_size:\n",
    "        video_path = launch_inference()\n",
    "        return video_path\n",
    "\n",
    "    # Get the total number of frames from the 'data_frame' field in the loaded sync data.\n",
    "    total_frames = video_total_frames if inference_all else duration\n",
    "    print(f\"Found {total_frames} frames to inference.\")\n",
    "\n",
    "    # Calculate segments\n",
    "    num_segment = total_frames // step_size\n",
    "    final_segment = total_frames % step_size\n",
    "    if final_segment > 0:\n",
    "        num_segment += 1\n",
    "    else:\n",
    "        final_segment = step_size\n",
    "    \n",
    "    video_path = []\n",
    "\n",
    "    # Loop through each segment to perform inference\n",
    "    for i in range(num_segment):\n",
    "        start_frame_seg = i * step_size + start_frame\n",
    "        end_frame_seg = (i+1) * step_size + start_frame if i != num_segment-1 else i * step_size + final_segment + start_frame\n",
    "\n",
    "        # Progress bar\n",
    "        percent = (i + 1) / num_segment * 100\n",
    "        bar_length = 50\n",
    "        filled_length = int(bar_length * (i + 1) // num_segment)\n",
    "        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)\n",
    "\n",
    "        sys.stdout.write(f'\\rProgress: |{bar}| {percent:.2f}% ({i + 1}/{num_segment} segments) -  ')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Call the inference function for the current segment\n",
    "        path = launch_inference(max_num_samples=end_frame_seg,start_sample=start_frame_seg)\n",
    "        video_path.append(f\"{path}\\n\")\n",
    "\n",
    "    merge_pred()\n",
    "    sys.stdout.write('\\nDone!\\n')\n",
    "    sys.stdout.flush()\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"io.yaml\" not in os.listdir(EXPROOT):\n",
    "    generate_io_yaml()\n",
    "\n",
    "COM_dir = os.path.join(EXPROOT,\"com\",\"predict00\")\n",
    "os.makedirs(COM_dir,exist_ok=True)\n",
    "\n",
    "if \"com3d.mat\" not in os.listdir(COM_dir):\n",
    "    print(f\"COM file not found in {COM_dir}, predicting COM now...\")\n",
    "    predict_com()\n",
    "\n",
    "if \"sync_dannce.mat\" not in os.listdir(EXPROOT):\n",
    "    sync_file = [f for f in os.listdir(EXPROOT) if f.endswith(\"_dannce.mat\")]\n",
    "    if sync_file:\n",
    "        sync_path = os.path.join(EXPROOT, sync_file[0])\n",
    "        video_path = segmented_and_call_inference(sync_path=sync_path)\n",
    "        print(f\"Inferenced video saved to {video_path}\")\n",
    "    else:\n",
    "        print(\"Error: No sync file found in project folder.\")\n",
    "else:\n",
    "    video_path = segmented_and_call_inference()\n",
    "    if not SKIP_VIDEO:\n",
    "        print(f\"Inferenced video saved to {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdannce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
