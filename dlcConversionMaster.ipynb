{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37813a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap2dlc = False\n",
    "l3d2dlc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d419e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# DeepLabCut Toolbox (deeplabcut.org)\n",
    "# © A. & M.W. Mathis Labs\n",
    "# https://github.com/DeepLabCut/DeepLabCut\n",
    "#\n",
    "# Please see AUTHORS for contributors.\n",
    "# https://github.com/DeepLabCut/DeepLabCut/blob/master/AUTHORS\n",
    "#\n",
    "# Licensed under GNU Lesser General Public License v3.0\n",
    "#\n",
    "\"\"\"\n",
    "DeepLabCut2.0 Toolbox (deeplabcut.org)\n",
    "© A. & M. Mathis Labs\n",
    "https://github.com/DeepLabCut/DeepLabCut\n",
    "Please see AUTHORS for contributors.\n",
    "\n",
    "https://github.com/DeepLabCut/DeepLabCut/blob/master/AUTHORS\n",
    "Licensed under GNU Lesser General Public License v3.0\n",
    "\"\"\"\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "\n",
    "SUPPORTED_FILETYPES = \"csv\", \"nwb\"\n",
    "\n",
    "def convertcsv2h5(config, scorer=None):\n",
    "    \"\"\"\n",
    "    Convert (image) annotation files in folder labeled-data from csv to h5.\n",
    "    This function allows the user to manually edit the csv (e.g. to correct the scorer name and then convert it into hdf format).\n",
    "    WARNING: conversion might corrupt the data.\n",
    "\n",
    "    config : string\n",
    "        Full path of the config.yaml file as a string.\n",
    "\n",
    "    scorer: string, optional\n",
    "        If a string is given, then the scorer/annotator in all csv and hdf files that are changed, will be overwritten with this name.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Convert csv annotation files for reaching-task project into hdf.\n",
    "    >>> deeplabcut.convertcsv2h5('/analysis/project/reaching-task/config.yaml')\n",
    "\n",
    "    --------\n",
    "    Convert csv annotation files for reaching-task project into hdf while changing the scorer/annotator in all annotation files to Albert!\n",
    "    >>> deeplabcut.convertcsv2h5('/analysis/project/reaching-task/config.yaml',scorer='Albert')\n",
    "    --------\n",
    "    \"\"\"\n",
    "    cfg = auxiliaryfunctions.read_config(config)\n",
    "    videos = cfg[\"video_sets\"].keys()\n",
    "    video_names = [Path(i).stem for i in videos]\n",
    "    folders = [Path(config).parent / \"labeled-data\" / Path(i) for i in video_names]\n",
    "    if not scorer:\n",
    "        scorer = cfg[\"scorer\"]\n",
    "\n",
    "    for folder in folders:\n",
    "        try:\n",
    "                fn = os.path.join(\n",
    "                    str(folder), \"CollectedData_\" + cfg[\"scorer\"] + \".csv\"\n",
    "                )\n",
    "                # Determine whether the data are single- or multi-animal without loading into memory\n",
    "                # simply by checking whether 'individuals' is in the second line of the CSV.\n",
    "                with open(fn) as datafile:\n",
    "                    head = list(islice(datafile, 0, 5))\n",
    "                if \"individuals\" in head[1]:\n",
    "                    header = list(range(4))\n",
    "                else:\n",
    "                    header = list(range(3))\n",
    "                if head[-1].split(\",\")[0] == \"labeled-data\":\n",
    "                    index_col = [0, 1, 2]\n",
    "                else:\n",
    "                    index_col = 0\n",
    "                data = pd.read_csv(fn, index_col=index_col, header=header)\n",
    "                data.columns = data.columns.set_levels([scorer], level=\"scorer\")\n",
    "                guarantee_multiindex_rows(data)\n",
    "                data.to_hdf(fn.replace(\".csv\", \".h5\"), key=\"df_with_missing\", mode=\"w\")\n",
    "                data.to_csv(fn)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Attention:\", folder, \"does not appear to have labeled data!\")\n",
    "\n",
    "def guarantee_multiindex_rows(df):\n",
    "    # Make paths platform-agnostic if they are not already\n",
    "    if not isinstance(df.index, pd.MultiIndex):  # Backwards compatibility\n",
    "        path = df.index[0]\n",
    "        try:\n",
    "            sep = \"/\" if \"/\" in path else \"\\\\\"\n",
    "            splits = tuple(df.index.str.split(sep))\n",
    "            df.index = pd.MultiIndex.from_tuples(splits)\n",
    "        except TypeError:  #  Ignore numerical index of frame indices\n",
    "            pass\n",
    "\n",
    "    # Ensure folder names are strings\n",
    "    try:\n",
    "        df.index = df.index.set_levels(df.index.levels[1].astype(str), level=1)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "def convert_sleap_to_deeplabcut(\n",
    "    sleap_file: str | Path,\n",
    "    deeplabcut_dir: str,\n",
    "    scorer: str = \"me\",\n",
    "    multianimal: bool = False,\n",
    "    max_instances: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a SLEAP project into a DeepLabCut project\n",
    "    WARNING: Conversion might corrupt the data.\n",
    "\n",
    "    Once conversion is complete, you will need to manually create a DeepLabCut config.yaml file based\n",
    "    on the keypoint names in the generated .csv files.\n",
    "    Finally, run deeplabcut.convertcsv2h5('config.yaml')\n",
    "\n",
    "    Args:\n",
    "        sleap_file : string | Path\n",
    "            Path to the .slp file.\n",
    "        deeplabcut_dir: string\n",
    "            Output directory.\n",
    "        scorer: string, optional\n",
    "            Name of scorer.\n",
    "        multi: boolean, optional\n",
    "            If True, the output will be formatted for a maDLC project.\n",
    "        max_instances: int, optional\n",
    "            Maximum number of instances (animals) to include per frame.\n",
    "            This will define the number of individuals expected in the DLC output\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"scorer\": scorer,\n",
    "        \"multianimalproject\": multianimal,\n",
    "        \"date\": time.strftime(\"%Y-%m-%d\"),\n",
    "        \"Task\": f\"{scorer}-{sleap_file.split('labels.')[1].rsplit('.pkg.slp', 1)[0]}\",\n",
    "        \"project_path\": deeplabcut_dir,\n",
    "        \"engine\": \"pytorch\",\n",
    "        \"video_sets\": {},\n",
    "        \"start\": 0,\n",
    "        \"stop\": 1,\n",
    "        \"numframes2pick\": 20,\n",
    "        \"skeleton_color\": \"white\",\n",
    "        \"pcutoff\": 0.6,\n",
    "        \"dotsize\": 12,\n",
    "        \"alphavalue\": 0.6,\n",
    "        \"colormap\": \"rainbow\",\n",
    "        \"TrainingFraction\": [0.95],\n",
    "        \"iteration\": 0,\n",
    "        \"default_net_type\": \"resnet_50\",\n",
    "        \"default_augmenter\": \"default\",\n",
    "        \"snapshotindex\": -1,\n",
    "        \"detector_snapshotindex\": -1,\n",
    "        \"batch_size\": 8,\n",
    "        \"detector_batch_size\": 1,\n",
    "        \"cropping\": False,\n",
    "        \"x1\": 0,\n",
    "        \"x2\": 640,\n",
    "        \"y1\": 277,\n",
    "        \"y2\": 624,\n",
    "        \"corner2move2\": [50, 50],\n",
    "        \"move2corner\": True,\n",
    "        \"SuperAnimalConversionTables\": None,\n",
    "    }\n",
    "\n",
    "    # create directories\n",
    "    if not os.path.exists(deeplabcut_dir):\n",
    "        os.makedirs(deeplabcut_dir)\n",
    "        os.makedirs(os.path.join(deeplabcut_dir, \"labeled-data\"))\n",
    "        os.makedirs(os.path.join(deeplabcut_dir, \"videos\"))\n",
    "\n",
    "    # parse .slp file\n",
    "    with h5py.File(sleap_file, \"r\") as hdf_file:\n",
    "        # Identify video names\n",
    "        video_names = {}\n",
    "        for video_group_name in hdf_file.keys():\n",
    "            if video_group_name.startswith(\"video\"):\n",
    "                source_video_path = f\"{video_group_name}/source_video\"\n",
    "                if source_video_path in hdf_file:\n",
    "                    source_video_json = hdf_file[source_video_path].attrs[\"json\"]\n",
    "                    source_video_dict = json.loads(source_video_json)\n",
    "                    video_filename = source_video_dict[\"backend\"][\"filename\"]\n",
    "                    video_names[video_group_name] = video_filename\n",
    "\n",
    "\n",
    "        # Read sleap track data\n",
    "        track_index_to_identifier = {}\n",
    "        display_individuals = []\n",
    "        if \"tracks_json\" in hdf_file:\n",
    "            tracks_dataset = hdf_file[\"tracks_json\"]\n",
    "            tracks_json_raw = tracks_dataset[:]\n",
    "            for i, track_bytes in enumerate(tracks_json_raw):\n",
    "                track_string = track_bytes.decode('utf-8')\n",
    "                track_list = json.loads(track_string)\n",
    "\n",
    "                if isinstance(track_list, list) and len(track_list) >= 2:\n",
    "                    track_identifier = str(track_list[1]) # Ensure it's a string, e.g., \"1\", \"2\", \"Mouse1\"\n",
    "                    track_index_to_identifier[i] = track_identifier\n",
    "                    display_individuals.append(track_identifier)\n",
    "        else:\n",
    "            print(\"Warning: 'tracks_json' dataset not found in SLEAP file.\")\n",
    "\n",
    "        # Handle track data according to multianimal and max_instance setting\n",
    "        if not multianimal:\n",
    "            display_individuals = [\"1\"] # Default single animal identity\n",
    "            track_index_to_identifier = {0: \"1\"} # Map SLEAP's first track (index 0) to \"1\"\n",
    "            max_instances = 1 # Force max_instances to 1 for single animal mode\n",
    "        else:\n",
    "            # If tracks_json didn't provide enough identities, or if it's missing, generate default ones up to max_instances.\n",
    "            if len(display_individuals) < max_instances:\n",
    "                for i in range(len(display_individuals), max_instances):\n",
    "                    default_name = str(i + 1)\n",
    "                    display_individuals.append(default_name)\n",
    "                    # Also update mapping for these default individuals\n",
    "                    if i not in track_index_to_identifier:\n",
    "                        track_index_to_identifier[i] = default_name\n",
    "            # If more tracks were detected than max_instances, truncate to max_instances\n",
    "            elif len(display_individuals) > max_instances:\n",
    "                display_individuals = display_individuals[:max_instances]\n",
    "                # Rebuild track_index_to_identifier to match the truncated list\n",
    "                track_index_to_identifier = {\n",
    "                    i: display_individuals[i] for i in range(max_instances)\n",
    "                }\n",
    "\n",
    "        print(f\"Identified individuals for DLC: {display_individuals}\")\n",
    "        print(f\"Internal track index to display identifier mapping: {track_index_to_identifier}\")\n",
    "            \n",
    "        # Extract and save images for each video\n",
    "        for video_group, video_filename in video_names.items():\n",
    "            data_frames = []\n",
    "            scorer_row, bodyparts_row, coords_row = None, None, None\n",
    "            output_dir = os.path.join(\n",
    "                deeplabcut_dir,\n",
    "                \"labeled-data\",\n",
    "                os.path.basename(video_filename).split(\".\")[0],\n",
    "            )\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            # extract labeled frames and save them in a separate directory for each video\n",
    "            if video_group in hdf_file and \"video\" in hdf_file[video_group]:\n",
    "                video_data = hdf_file[f\"{video_group}/video\"][:]\n",
    "                frame_numbers = hdf_file[f\"{video_group}/frame_numbers\"][:]\n",
    "                frame_names = []\n",
    "                for i, (img_bytes, frame_number) in enumerate(\n",
    "                    zip(video_data, frame_numbers)\n",
    "                ):\n",
    "                    img = Image.open(io.BytesIO(np.array(img_bytes, dtype=np.uint8)))\n",
    "                    img = np.array(img)\n",
    "                    if i == 0:\n",
    "                        video_path = os.path.join(\n",
    "                            deeplabcut_dir,\n",
    "                            \"videos\",\n",
    "                            video_names[video_group].split(\"/\")[-1],\n",
    "                        )\n",
    "                        config[\"video_sets\"][video_path] = {\n",
    "                            \"crop\": f\"0, {img.shape[1]}, 0, {img.shape[0]}\"\n",
    "                        }\n",
    "                    frame_name = f\"img{str(frame_number).zfill(8)}.png\"\n",
    "                    cv2.imwrite(f\"{output_dir}/{frame_name}\", img)\n",
    "                    frame_names.append(frame_name)\n",
    "                    print(f\"Saved frame {frame_number} as {frame_name}\")\n",
    "\n",
    "            # extract coordinates and save them in a separate directory for each video\n",
    "            if video_group in hdf_file and \"frames\" in hdf_file:\n",
    "                frames_dataset = hdf_file[\"frames\"]\n",
    "                frame_references = {\n",
    "                    frame[\"frame_id\"]: frame[\"frame_idx\"]\n",
    "                    for frame in frames_dataset\n",
    "                    if frame[\"video\"] == int(video_group.replace(\"video\", \"\"))\n",
    "                }\n",
    "\n",
    "                # Extract instances and points\n",
    "                points_dataset = hdf_file[\"points\"]\n",
    "                instances_dataset = hdf_file[\"instances\"]\n",
    "\n",
    "                # Pre-process instances_data\n",
    "                instances_paired = {}\n",
    "                for instance_entry in instances_dataset:\n",
    "                    frame_id = instance_entry['frame_id']\n",
    "                    track_id = instance_entry['track']\n",
    "                    if frame_id not in instances_paired:\n",
    "                        instances_paired[frame_id] = {}\n",
    "                    instances_paired[frame_id][track_id] = instance_entry\n",
    "\n",
    "                data = []\n",
    "\n",
    "                # parse data\n",
    "                metadata_json = hdf_file[\"metadata\"].attrs[\"json\"]\n",
    "                metadata_dict = json.loads(metadata_json)\n",
    "                nodes = metadata_dict[\"nodes\"]\n",
    "                links = metadata_dict[\"skeletons\"][0][\"links\"]\n",
    "\n",
    "                keypoints = [node[\"name\"] for node in nodes]\n",
    "                skeleton = [\n",
    "                    [keypoints[l[\"source\"]], keypoints[l[\"target\"]]] for l in links\n",
    "                ]\n",
    "                config[\"skeleton\"] = skeleton\n",
    "\n",
    "                keypoints_ids = [\n",
    "                    n[\"id\"] for n in metadata_dict[\"skeletons\"][0][\"nodes\"]\n",
    "                ]\n",
    "                keypoints_ordered = [keypoints[idx] for idx in keypoints_ids]\n",
    "\n",
    "                # Iterate through the frames\n",
    "                for frame_id in frame_references.keys():\n",
    "                    current_frame_instances = instances_paired.get(frame_id, {})\n",
    "                    # Initialize temporary structure to hold keypoints for each track\n",
    "\n",
    "                    frame_keypoint_track = {\n",
    "                        idx: {kp: (np.nan, np.nan) for kp in keypoints_ordered}\n",
    "                        for idx in track_index_to_identifier.keys()\n",
    "                    }\n",
    "                    \n",
    "                    for internal_track_index, instance_info in current_frame_instances.items():\n",
    "                        point_id_start = instance_info[\"point_id_start\"]\n",
    "                        point_id_end = instance_info[\"point_id_end\"]\n",
    "\n",
    "                        if internal_track_index in track_index_to_identifier:\n",
    "                            instance_points = points_dataset[point_id_start:point_id_end]\n",
    "\n",
    "                            for node_idx, kp in enumerate(instance_points):\n",
    "                                x, y, vis = kp[\"x\"], kp[\"y\"], kp[\"visible\"]\n",
    "                                node_name = keypoints_ordered[node_idx]\n",
    "                                if np.isnan(x) or np.isnan(y) or vis == False:\n",
    "                                    x, y = None, None\n",
    "                                frame_keypoint_track[internal_track_index][node_name] = (x,y)\n",
    "\n",
    "                    keypoints_flat = []\n",
    "\n",
    "                    # Flatten the keypoints of each track\n",
    "                    for internal_track_idx in sorted(track_index_to_identifier.keys()):\n",
    "                        track_kp_data = frame_keypoint_track.get(internal_track_idx)\n",
    "                        if track_kp_data:\n",
    "                            for kp in keypoints_ordered:\n",
    "                                x, y = track_kp_data.get(kp, (np.nan, np.nan))\n",
    "                                keypoints_flat.extend([x, y])\n",
    "                        else:\n",
    "                            for _ in keypoints_ordered:\n",
    "                                keypoints_flat.extend([np.nan, np.nan])\n",
    "\n",
    "                    frame_idx = frame_references[frame_id]\n",
    "                    data.append([frame_idx] + keypoints_flat)\n",
    "\n",
    "                # Construct DLC Header Rows\n",
    "                individuals_row = [\"individuals\"]\n",
    "                bodyparts_row = [\"bodyparts\"]\n",
    "                columns = [\"frame\"]\n",
    "                coords_row = [\"coords\"]\n",
    "\n",
    "                num_keypoints = len(keypoints_ordered)\n",
    "                num_individuals = len(display_individuals) if multianimal else 1\n",
    "\n",
    "                if not multianimal:\n",
    "                    config[\"bodyparts\"] = keypoints_ordered\n",
    "                    config[\"individuals\"] = None\n",
    "                    columns += ([f\"{kp}_x\" for kp in keypoints_ordered] + [f\"{kp}_y\" for kp in keypoints_ordered])\n",
    "                    bodyparts_row += [ f\"{kp}\" for kp in keypoints_ordered for _ in (0, 1) ]\n",
    "                    coords_row += ([\"x\", \"y\"] * num_keypoints)\n",
    "                else:\n",
    "                    config[\"bodyparts\"] = \"MULTI!\"\n",
    "                    config[\"multianimalbodyparts\"] = keypoints_ordered\n",
    "                    config[\"uniquebodyparts\"] = []\n",
    "                    individuals = [str(k) for k in range(1,max_instances+1)]\n",
    "                    config[\"individuals\"] = individuals\n",
    "                    config[\"identity\"] = False\n",
    "                    for m in range(num_individuals):\n",
    "                        columns += ([f\"{kp}_x\" for kp in keypoints_ordered] + [f\"{kp}_y\" for kp in keypoints_ordered])\n",
    "                        bodyparts_row += [ f\"{kp}\" for kp in keypoints_ordered for _ in (0, 1) ]\n",
    "                        coords_row += ([\"x\", \"y\"] * num_keypoints)\n",
    "                        for _ in range(num_keypoints*2):\n",
    "                            individuals_row += [individuals[m]]\n",
    "\n",
    "                scorer_row = [\"scorer\"] + [f\"{scorer}\"] * (len(columns) - 1)\n",
    "\n",
    "                labels_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "                video_base_name = os.path.basename(video_filename).split(\".\")[0]\n",
    "                labels_df[\"frame\"] = labels_df[\"frame\"].apply(\n",
    "                    lambda x: (\n",
    "                        f\"labeled-data/{video_base_name}/\"\n",
    "                        f\"img{str(int(x)).zfill(8)}.png\"\n",
    "                    )\n",
    "                )\n",
    "                labels_df = labels_df.groupby(\"frame\", as_index=False).first()\n",
    "                data_frames.append(labels_df)\n",
    "\n",
    "                # Combine all data frames into a single DataFrame\n",
    "                combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "                header_df = pd.DataFrame(\n",
    "                    [row for row in [scorer_row, individuals_row, bodyparts_row, coords_row] if row != individuals_row or multianimal],\n",
    "                    columns=combined_df.columns\n",
    "                )\n",
    "\n",
    "                final_df = pd.concat([header_df, combined_df], ignore_index=True)\n",
    "                final_df.columns = [None] * len(final_df.columns)  # Set header to None\n",
    "\n",
    "                # Save concatenated labels\n",
    "                final_df.to_csv(\n",
    "                    os.path.join(output_dir, f\"CollectedData_{scorer}.csv\"),\n",
    "                    index=False,\n",
    "                    header=None,\n",
    "                )\n",
    "\n",
    "    with open(os.path.join(deeplabcut_dir, \"config.yaml\"), \"w\") as outfile:\n",
    "        yaml.dump(config, outfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def convert_Label3D_to_deeplabcut(\n",
    "    Label3D_file: str | Path,\n",
    "    skeleton_file: str | Path,\n",
    "    deeplabcut_dir: str,\n",
    "    scorer: str = \"me\",\n",
    "    COM: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a Label3D label into a DeepLabCut project\n",
    "    WARNING: Conversion might corrupt the data.\n",
    "    Once conversion is complete, run deeplabcut.convertcsv2h5('config.yaml')\n",
    "    Args:\n",
    "        Label3D_file : string | Path\n",
    "            Path to the exported Label3D_dannce.mat file.\n",
    "        skeleton_file : string | Path\n",
    "            Label3D skeleton used during label\n",
    "        deeplabcut_dir: string\n",
    "            Output directory.\n",
    "        scorer: string, optional\n",
    "            Name of scorer.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"scorer\": scorer,\n",
    "        \"multianimalproject\": False,\n",
    "        \"date\": time.strftime(\"%Y-%m-%d\"),\n",
    "        \"Task\": f\"{scorer}-{Label3D_file.split('/')[-1].rsplit('.mat', 1)[0]}\",\n",
    "        \"identity\": None,\n",
    "        \"project_path\": deeplabcut_dir,\n",
    "        \"engine\": \"pytorch\",\n",
    "        \"video_sets\": {},\n",
    "        \"start\": 0,\n",
    "        \"stop\": 1,\n",
    "        \"numframes2pick\": 20,\n",
    "        \"skeleton_color\": \"white\",\n",
    "        \"pcutoff\": 0.6,\n",
    "        \"dotsize\": 12,\n",
    "        \"alphavalue\": 0.6,\n",
    "        \"colormap\": \"rainbow\",\n",
    "        \"TrainingFraction\": [0.95],\n",
    "        \"iteration\": 0,\n",
    "        \"default_net_type\": \"resnet_50\",\n",
    "        \"default_augmenter\": \"default\",\n",
    "        \"snapshotindex\": -1,\n",
    "        \"detector_snapshotindex\": -1,\n",
    "        \"batch_size\": 8,\n",
    "        \"detector_batch_size\": 1,\n",
    "        \"cropping\": False,\n",
    "        \"x1\": 224,\n",
    "        \"x2\": 736,\n",
    "        \"y1\": 14,\n",
    "        \"y2\": 526,\n",
    "        \"corner2move2\": [50, 50],\n",
    "        \"move2corner\": True,\n",
    "        \"SuperAnimalConversionTables\": None,\n",
    "    }\n",
    "\n",
    "    # create directories\n",
    "    if not os.path.exists(deeplabcut_dir):\n",
    "        os.makedirs(deeplabcut_dir)\n",
    "        os.makedirs(os.path.join(deeplabcut_dir, \"labeled-data\"))\n",
    "        os.makedirs(os.path.join(deeplabcut_dir, \"videos\"))\n",
    "\n",
    "    # parse .mat file\n",
    "    label_data = sio.loadmat(Label3D_file)\n",
    "    skeleton_data = sio.loadmat(skeleton_file)\n",
    "\n",
    "    # Extract bodyparts and skeletons from skeleton file\n",
    "    bodyparts = [str(bp[0]) for bp in skeleton_data['joint_names'][0]] if not COM else [\"com\",\"com2\"]\n",
    "\n",
    "    links = skeleton_data[\"joints_idx\"]\n",
    "\n",
    "    skeleton = []\n",
    "    if not COM:\n",
    "        for i in range(0,len(links)):\n",
    "            l = links[i,:]\n",
    "            skeleton.append([bodyparts[l[0]-1], bodyparts[l[1]-1]])\n",
    "        \n",
    "    config[\"skeleton\"] = skeleton\n",
    "    config[\"bodyparts\"] = bodyparts\n",
    "\n",
    "    print(f\"Extracted body parts: {bodyparts}\")\n",
    "    print(skeleton)\n",
    "\n",
    "    # Access labelData, which is a 4x1 cell array of structs\n",
    "    label_data_cells = label_data['labelData'][:,0]\n",
    "\n",
    "    # Iterate through each camera view\n",
    "    for cam_idx, cam_struct in enumerate(label_data_cells):\n",
    "        # Extract 2D points for the current camera view\n",
    "        data_2d = cam_struct['data_2d'][0,0]\n",
    "        data_sampleID = cam_struct['data_sampleID'][0,0]\n",
    "\n",
    "        if data_2d.size == 0 or data_sampleID.size == 0:\n",
    "            print(f\"Camera {cam_idx}'s data_2d or data_sampleID is empty! Skipping camera {cam_idx}.\")\n",
    "        else:\n",
    "            num_frames = data_2d.shape[0]\n",
    "            num_bodyparts = len(bodyparts)\n",
    "\n",
    "            # Reshape data_2d to (num_frames, num_bodyparts, 2) for x, y coordinates\n",
    "            points_2d = data_2d.reshape(num_frames, num_bodyparts, 2)\n",
    "\n",
    "            # Generate unique video name for each camera view\n",
    "            base_video_name = Path(Label3D_file).stem.replace('_dannce', '')\n",
    "            video_name = f\"{base_video_name}_cam{cam_idx + 1}\"\n",
    "            video_base_name = os.path.join(deeplabcut_dir, \"videos\", f\"{video_name}.mp4\")\n",
    "            config[\"video_sets\"][video_base_name] = {\"crop\": [0, 0, 640, 480]}\n",
    "\n",
    "            # Create a MultiIndex DataFrame for DLC for the current camera view\n",
    "            columns = pd.MultiIndex.from_product(\n",
    "                [[scorer], bodyparts, ['x', 'y']],\n",
    "                names=['scorer', 'bodyparts', 'coords']\n",
    "            )\n",
    "            data_df = pd.DataFrame(index=data_sampleID.flatten(), columns=columns, dtype=float)\n",
    "\n",
    "            # Populate the DataFrame\n",
    "            for frame_idx, sampleID in enumerate(data_sampleID.flatten()):\n",
    "                for bp_idx, bp_name in enumerate(bodyparts):\n",
    "                    x = points_2d[frame_idx, bp_idx, 0]\n",
    "                    y = points_2d[frame_idx, bp_idx, 1]\n",
    "                    data_df.loc[sampleID, (scorer, bp_name, 'x')] = x\n",
    "                    data_df.loc[sampleID, (scorer, bp_name, 'y')] = y\n",
    "\n",
    "            # Generate image paths for the index\n",
    "            image_paths = [f\"labeled-data/{video_name}/img{str(int(sampleID)).zfill(8)}.png\" for sampleID in data_sampleID.flatten()]\n",
    "            data_df.index = image_paths\n",
    "\n",
    "            # Extract frames using FFmpeg\n",
    "            video_base_dir = os.path.dirname(Label3D_file)\n",
    "            input_video_path = os.path.join(video_base_dir, \"Videos\", f\"Camera{cam_idx + 1}\", \"0.mp4\")\n",
    "            output_labeled_data_dir = os.path.join(deeplabcut_dir, \"labeled-data\", video_name)\n",
    "            os.makedirs(output_labeled_data_dir, exist_ok=True) # Ensure directory exists\n",
    "            print(f\"Extracting frames for {video_name} from {input_video_path}\")\n",
    "\n",
    "            # Iterate through sampleIDs and extract corresponding frames\n",
    "            for frame_idx, sampleID in enumerate(data_sampleID.flatten()):\n",
    "                output_image_path_relative = data_df.index[frame_idx]\n",
    "                # Construct the full absolute path for the output image\n",
    "                full_output_image_path = os.path.join(deeplabcut_dir, output_image_path_relative)\n",
    "\n",
    "                if os.path.isfile(full_output_image_path):\n",
    "                    print(f\"Frame {frame_idx} already in the {deeplabcut_dir}, skipping...\")\n",
    "                    continue\n",
    "                else:\n",
    "                    ffmpeg_command = f'ffmpeg -y -i \"{input_video_path}\" -vf select=\"eq(n\\,{int(sampleID)})\" -vframes 1 \"{full_output_image_path}\"'\n",
    "                    try:\n",
    "                        subprocess.run(ffmpeg_command, shell=True, check=True, capture_output=True, text=True)\n",
    "                        print(f\"Successfully extracted frame {sampleID}.\")\n",
    "                    except subprocess.CalledProcessError as e:\n",
    "                        print(f\"Error extracting frame {sampleID}: {e}\")\n",
    "                        print(f\"Stderr: {e.stderr}\")\n",
    "                        print(f\"Stdout: {e.stdout}\")\n",
    "\n",
    "            # Save the DataFrame to CSV for the current camera view\n",
    "            csv_output_path = os.path.join(output_labeled_data_dir, f\"CollectedData_{scorer}.csv\")\n",
    "            data_df.to_csv(csv_output_path, index=True, header=True)\n",
    "            print(f\"Labeled data for {video_name} saved to: {csv_output_path}\")\n",
    "\n",
    "            # Copy videos to DLC project\n",
    "            output_video_path = os.path.join(deeplabcut_dir, \"videos\")\n",
    "            if os.path.isfile(os.path.join(output_video_path, f\"{video_name}.mp4\")):\n",
    "                print(f\"{video_name}.mp4 already in the DLC folder, skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Copying {video_name}.mp4 to DLC folder...\")\n",
    "                shutil.copy(input_video_path, output_video_path)\n",
    "                video_old_file = os.path.join(output_video_path, \"0.mp4\")\n",
    "                video_new_name = os.path.join(output_video_path, f\"{video_name}.mp4\")\n",
    "                os.rename(video_old_file, video_new_name)\n",
    "\n",
    "        # Save config.yaml (this should be done once after all video_sets are populated)\n",
    "        config_path = os.path.join(deeplabcut_dir, \"config.yaml\")\n",
    "        if os.path.isfile(config_path):\n",
    "            config_backup = os.path.join(deeplabcut_dir, \"config_bak.yaml\")\n",
    "            print(\"Config file already existed, renamed the original config as config_bak.yaml\")\n",
    "            shutil.copy(config_path,config_backup)\n",
    "            with open(config_path, 'r') as f:\n",
    "                config_org = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "                config_org[\"video_sets\"].update(config[\"video_sets\"])\n",
    "                print(\"Appended new video_sets to the originals.\")\n",
    "            with open(config_path, 'w') as file:\n",
    "                yaml.dump(config_org, file, default_flow_style=False, sort_keys=False)\n",
    "                print(f\"DeepLabCut config in {config_path} has been updated.\")\n",
    "        else:\n",
    "            with open(config_path, 'w') as f:\n",
    "                yaml.dump(config, f, sort_keys=False)\n",
    "            print(f\"DeepLabCut config saved to: {config_path}\")\n",
    "        print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sleap2dlc and not l3d2dlc:\n",
    "    sleapfile = 'D:\\Project\\Sleap-Models\\BTR\\labels.double.pkg.slp'\n",
    "    dlcdir = 'D:\\Project\\DLC-Models\\Double'\n",
    "    convert_sleap_to_deeplabcut(sleapfile,dlcdir,\"bezver\",True)\n",
    "\n",
    "    configfile = os.path.join(dlcdir,\"config.yaml\")\n",
    "    convertcsv2h5(configfile)\n",
    "\n",
    "elif l3d2dlc and not sleap2dlc:\n",
    "    Label3D_file = \"D:/Project/SDANNCE-Models/4CAM-250620/SD-20250705-MULTI/SD-20250705-MULTI-COM3D.mat\"\n",
    "    skeleton_file = \"D:/Repository/Label3D/skeletons/com-multi.mat\"\n",
    "    dlcdir = 'D:\\Project\\DLC-Models\\COM3D'\n",
    "    convert_Label3D_to_deeplabcut(Label3D_file,skeleton_file,dlcdir,\"bezver\",COM=True)\n",
    "\n",
    "    configfile = os.path.join(dlcdir,\"config.yaml\")\n",
    "    convertcsv2h5(configfile)\n",
    "\n",
    "else:\n",
    "    # If neither, just convert csv2h5\n",
    "    dlcdir = 'D:\\Project\\DLC-Models\\COM3D'\n",
    "    configfile = os.path.join(dlcdir,\"config.yaml\")\n",
    "    convertcsv2h5(configfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplabcut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
